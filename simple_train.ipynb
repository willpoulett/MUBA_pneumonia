{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['PNEUMONIA', 'NORMAL']\n",
    "img_size = 150\n",
    "\n",
    "def get_training_data(data_dir):\n",
    "    data = [] \n",
    "    for label in labels: \n",
    "        path = os.path.join(data_dir, label)\n",
    "        class_num = labels.index(label)\n",
    "        for img in os.listdir(path):\n",
    "            \n",
    "            img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "            resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n",
    "            data.append([resized_arr, class_num])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_training_data('./chest_xray/train')\n",
    "test = get_training_data('./chest_xray/test')\n",
    "val = get_training_data('./chest_xray/val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(val))\n",
    "# Validation is only 16 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pneumnoia_count = 0\n",
    "normal_count = 0\n",
    "for image in train:\n",
    "    if(image[1] == 0): # A 0 is the pneumonia class\n",
    "        pneumnoia_count += 1\n",
    "    else:\n",
    "        normal_count += 1\n",
    "\n",
    "print(\"Pneumonia Cases: \", pneumnoia_count)\n",
    "print(\"Normal Cases: \", normal_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at first training image\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train[0][0], cmap='gray')\n",
    "plt.title(labels[train[0][1]])\n",
    "\n",
    "# Look at final training image\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.imshow(train[-1][0], cmap='gray')\n",
    "plt.title(labels[train[-1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "x_test_B = []\n",
    "y_test_B = []\n",
    "\n",
    "\n",
    "for feature, label in train:\n",
    "    x_train.append(feature)\n",
    "    y_train.append(label)\n",
    "\n",
    "for feature, label in test:\n",
    "    x_test_B.append(feature)\n",
    "    y_test_B.append(label)\n",
    "    \n",
    "random_sample = 100\n",
    "\n",
    "x_train, x_test_val, y_train, y_test_val   = train_test_split(x_train, y_train, test_size=0.1, random_state=random_sample)\n",
    "x_val,   x_test_A,   y_val,   y_test_A     = train_test_split(x_test_val, y_test_val, test_size=0.5, random_state=random_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_val))\n",
    "print(len(x_test_A))\n",
    "print(len(x_test_B))\n",
    "print(x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "x_train = np.array(x_train) / 255\n",
    "x_val = np.array(x_val) / 255\n",
    "x_test_A = np.array(x_test_A) / 255\n",
    "x_test_B = np.array(x_test_A) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize data for deep learning \n",
    "x_train = x_train.reshape(-1, img_size, img_size, 1)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_val = x_val.reshape(-1, img_size, img_size, 1)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "x_test_A = x_test_A.reshape(-1, img_size, img_size, 1)\n",
    "y_test_A = np.array(y_test_A)\n",
    "\n",
    "x_test_B = x_test_B.reshape(-1, img_size, img_size, 1)\n",
    "y_test_B = np.array(y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset, dataset_name in zip([y_train,y_val,y_test_A,y_test_B],[\"y_train\",\"y_val\",\"y_test_A\",\"y_test_B\"]):\n",
    "    pneumnoia_count = 0\n",
    "    normal_count = 0\n",
    "    for label in dataset:\n",
    "        if(label == 0): # A 0 is the pneumonia class\n",
    "            pneumnoia_count += 1\n",
    "        else:\n",
    "            normal_count += 1\n",
    "    \n",
    "    print(f\"\\n{dataset_name}\")\n",
    "    print(\"Pneumonia Cases: \", pneumnoia_count)\n",
    "    print(\"Normal Cases: \", normal_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 128 , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(units = 1 , activation = 'sigmoid'))\n",
    "model.compile(optimizer = \"rmsprop\" , loss = 'binary_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)\n",
    "best_model = keras.callbacks.ModelCheckpoint(filepath='models/best_model.h5', save_best_only=True)\n",
    "\n",
    "class CustomSaver(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % 5 == 0:  # or save after some epoch, each k-th epoch etc.\n",
    "            self.model.save(f\"models/model_epoch_{epoch}.h5\")\n",
    "\n",
    "\n",
    "epoch_saver = CustomSaver()\n",
    "#epoch_saver = keras.callbacks.ModelCheckpoint(filepath=\"models/model_epoch_{epoch:02d}.h5\", save_best_only=False, save_freq = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train, batch_size = 32, epochs = 60 , validation_data = (x_val, y_val) ,callbacks = [learning_rate_reduction,best_model,epoch_saver],)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
